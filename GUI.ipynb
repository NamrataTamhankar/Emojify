{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F \n",
    " \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, num_channel):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(num_channel, num_channel, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(num_channel, num_channel, 3, 1, 1),\n",
    "            nn.BatchNorm2d(num_channel))\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv_layer(inputs)\n",
    "        output = self.activation(output + inputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(DownBlock, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 3, 2, 1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, 3, 1, 1),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv_layer(inputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, is_last=False):\n",
    "        super(UpBlock, self).__init__()\n",
    "        self.is_last = is_last\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, in_channel, 3, 1, 1),\n",
    "            nn.BatchNorm2d(in_channel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_channel, out_channel, 3, 1, 1))\n",
    "        self.act = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.last_act = nn.Tanh()\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.conv_layer(inputs)\n",
    "        if self.is_last:\n",
    "            output = self.last_act(output)\n",
    "        else:\n",
    "            output = self.act(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self, num_channel=32, num_blocks=4):\n",
    "        super(SimpleGenerator, self).__init__()\n",
    "        self.down1 = DownBlock(3, num_channel)\n",
    "        self.down2 = DownBlock(num_channel, num_channel*2)\n",
    "        self.down3 = DownBlock(num_channel*2, num_channel*3)\n",
    "        self.down4 = DownBlock(num_channel*3, num_channel*4)\n",
    "        res_blocks = [ResBlock(num_channel*4)]*num_blocks\n",
    "        self.res_blocks = nn.Sequential(*res_blocks)\n",
    "        self.up1 = UpBlock(num_channel*4, num_channel*3)\n",
    "        self.up2 = UpBlock(num_channel*3, num_channel*2)\n",
    "        self.up3 = UpBlock(num_channel*2, num_channel)\n",
    "        self.up4 = UpBlock(num_channel, 3, is_last=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        down1 = self.down1(inputs)\n",
    "        down2 = self.down2(down1)\n",
    "        down3 = self.down3(down2)\n",
    "        down4 = self.down4(down3)\n",
    "        down4 = self.res_blocks(down4)\n",
    "        up1 = self.up1(down4)\n",
    "        up2 = self.up2(up1+down3)\n",
    "        up3 = self.up3(up2+down2)\n",
    "        up4 = self.up4(up3+down1)\n",
    "        return up4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter \n",
    "import cv2\n",
    "import os\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import time\n",
    "\n",
    "class App:\n",
    "    def __init__(self, window, window_title, video_source=0):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        self.video_source = video_source\n",
    "\n",
    "        # open video source (by default this will try to open the computer webcam)\n",
    "        self.vid = MyVideoCapture(self.video_source)\n",
    "\n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tkinter.Canvas(window, width = window.winfo_screenwidth(), height = window.winfo_screenheight())\n",
    "        self.canvas.pack(fill='both', expand=True)\n",
    "        bg = PIL.ImageTk.PhotoImage(PIL.Image.open(\"ss.png\"))\n",
    "        self.canvas.create_image(0, 0, image=bg, anchor='nw')\n",
    " \n",
    "        ts=time.strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        # Button that lets the user take a snapshot\n",
    "        self.btn_snapshot=tkinter.Button(window, text=\"Click a Snapshot\", width=50, command=lambda: self.snapshot(ts))\n",
    "        button1_window = self.canvas.create_window(800, 600, anchor='center', window=self.btn_snapshot)\n",
    "#         self.btn_snapshot.pack(anchor=tkinter.CENTER, expand=True)\n",
    "        # After it is called once, the update method will be automatically called every delay milliseconds\n",
    "        self.delay = 15\n",
    "        self.update()\n",
    " \n",
    "        self.window.mainloop()\n",
    "    \n",
    "    def emoj(self,ts):\n",
    "        weight = torch.load('weight.pth', map_location='cpu')\n",
    "        model = SimpleGenerator()\n",
    "        model.load_state_dict(weight)\n",
    "        #torch.save(model.state_dict(), 'weight.pth')\n",
    "        model.eval()\n",
    "        raw_image = cv2.imread(\"images/frame-\" +  ts + \".jpg\")\n",
    "#         cv2.imshow(\"cropped\", raw_image)\n",
    "        raw_image = cv2.resize(raw_image, (256,256), interpolation = cv2.INTER_AREA)\n",
    "        image = raw_image/127.5 - 1 \n",
    "        image = image.transpose(2, 0, 1) \n",
    "        image = torch.tensor(image).unsqueeze(0)\n",
    "        output = model(image.float())\n",
    "        output = output.squeeze(0).detach().numpy()\n",
    "        output = output.transpose(1, 2, 0)\n",
    "        output = (output + 1) * 127.5\n",
    "        output = np.clip(output, 0, 255).astype(np.uint8)\n",
    "        output = np.concatenate([raw_image, output], axis=0)\n",
    "        cv2.imwrite(\"results/frame-\" +  ts + \".jpg\", output)\n",
    "        cv2.imshow(\"emojy\", output)\n",
    "        \n",
    "    def faceid(self,ts):\n",
    "        import cv2\n",
    "        face_cascade = cv2.CascadeClassifier(r\"haarcascade_frontalface_default.xml\")\n",
    "        img = cv2.imread(\"input/frame-\" +  ts + \".jpg\")\n",
    "#         print(img)\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.05, minNeighbors=5)\n",
    " \n",
    "        for x, y, w, h in faces:\n",
    "            img = cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        resized = cv2.resize(img, (int(img.shape[1]), int(img.shape[0])))\n",
    "        cv2.imshow(\"Gray\", resized)\n",
    "        crop_img = img[y:y+h, x:x+w]\n",
    "#         cv2.imshow(\"cropped\", crop_img)\n",
    "        cv2.imwrite(\"images/frame-\" + ts + \".jpg\", crop_img)\n",
    "        self.emoj(ts)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows() \n",
    " \n",
    "    def snapshot(self,ts):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        path = 'input'\n",
    "        if ret:\n",
    "            cv2.imwrite(\"input/frame-\" + ts + \".jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
    "        self.faceid(ts)\n",
    "#         self.emoj(ts)\n",
    " \n",
    "\n",
    "    def update(self):\n",
    "        # Get a frame from the video source\n",
    "        ret, frame = self.vid.get_frame()\n",
    "\n",
    "        if ret:\n",
    "            self.photo = PIL.ImageTk.PhotoImage(image = PIL.Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image = self.photo, anchor = tkinter.NW)\n",
    "\n",
    "        self.window.after(self.delay, self.update)\n",
    "        \n",
    "class MyVideoCapture:\n",
    "    def __init__(self, video_source=0):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "\n",
    "\n",
    "# Create a window and pass it to the Application object\n",
    "App(tkinter.Toplevel(), \"Emojify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
